8/8/2019
	i should probably do some type of exploratory analysis of order effects in exps 2 / 3, cuz im sure jessecae will ask about it

	performance analyses
		i need marginal means for all significant effects
		change the difference X difficulty RT follow up to be the simple effect of difficulty at each level of difference

7/31/2019
  starting fixing performance analyses
  realized formatSimpleEffects() needs to be generalized to include instances where effects from simplified model aren't on second row

7/29/2019
  experiments 1 and 2 are successfully collected
    wooo, that was a rush

  ive quickly set up a bunch of analyses already, but now it's time to think carefully about everything that needs to be done

  things that still need to be done:
    exp 1
      investigate order effects
      learning rate analysis
        big caveat here is that it's just harder to detect the difference between 'switching medium amount' vs 'switching a lot' or 'switching medium' vs 'barely switching'
          the control you'd need is where people just detect frequency of switching without actually performing the switching
        done for now
    exp 2
      run choice analyses with and without trimming
      flesh out the rapid fire analysis
        make a decision on whether or not to use that data
        it's tough to know what info to go off of here
        i peeked at the effects, nothing really changes
        phase doesn't interact with the predictors
        when rapid fire data is included in the anova, the interaction term goes from 0.08 to 0.056

      a document for dealing with random effects
        make the case for why controlling for them is important
      other random exploratory stuff given the data i have
        correlating individual difference vars with choice

  im getting sucked down the random effects rabbit hole
  	i think im alright with it... 

7/22/2019
  preparation for day 1 of data collection:
    finish data pipeline
    make an analysis homepage
      which links to the different sub analysis pages
    don't forget to drop sandbox data from the pipeline
      done
    implement an rsync in ./downloadAndProcess instead of downloading every time
      done

    code up a quickSum.py that i can call from local
      done sort of
      used shortcuts instead, too complicated otherwise

  alright, it's go time

  sub journal:
    16:04
      4 total HITs active
      all assignments for all hits got scooped up p much immediately
      very few inits on the server, though